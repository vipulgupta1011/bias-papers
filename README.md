# Papers on bias in NLP

Here is a list of papers focused on bias in NLP. Please feel free to send a pull request if you want to add a paper.

## Quantifying bias

| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [Probing as Quantifying Inductive Bias](https://aclanthology.org/2022.acl-long.129.pdf) | ACL | 2022 |
| [Measuring Fairness of Text Classifiers via Prediction Sensitivity](https://aclanthology.org/2022.acl-long.401/) | ACL | 2022 |
| [Detecting Emergent Intersectional Biases: Contextualized Word Embeddings Contain a Distribution of Human-like Biases](https://dl.acm.org/doi/pdf/10.1145/3461702.3462536) | AIES | 2021 |
| [On Measuring and Mitigating Biased Inferences of Word Embeddings](https://arxiv.org/pdf/1908.09369.pdf) | AAAI | 2020 |
| [Reducing Sentiment Bias in Language Models via Counterfactual Evaluation](https://aclanthology.org/2020.findings-emnlp.7/) | EMNLP | 2020 |
| [Evaluating Gender Bias in Machine Translation](https://aclanthology.org/P19-1164.pdf) | ACL | 2019 |
| [Understanding Undesirable Word Embedding Associations](https://aclanthology.org/P19-1166.pdf) | ACL | 2019 |
| [Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting](https://www.microsoft.com/en-us/research/uploads/prod/2019/01/bios_bias.pdf) | FAccT | 2019 |


## Bias Mitigation

| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning](https://aclanthology.org/2022.aacl-main.61.pdf) | AACL | 2022 |
| [Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal](https://aclanthology.org/2022.findings-acl.55.pdf) | ACL | 2022 |
| [Entropy-based Attention Regularization Frees Unintended Bias Mitigation from Lists](https://aclanthology.org/2022.findings-acl.88/) | ACL | 2022 |
| [Learning Bias-reduced Word Embeddings Using Dictionary Definitions](https://aclanthology.org/2022.findings-acl.90.pdf) | ACL | 2022 |
| [Auto-Debias: Debiasing Masked Language Models with Automated Biased Prompts](https://aclanthology.org/2022.acl-long.72.pdf) | ACL | 2022 |
| [Balancing out Bias: Achieving Fairness Through Balanced Training](https://aclanthology.org/2022.emnlp-main.779.pdf)| EMNLP | 2022 |
| [Sustainable Modular Debiasing of Language Models](https://arxiv.org/pdf/2109.03646.pdf) | EMNLP | 2021 |
| [A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces](https://arxiv.org/pdf/1909.06092.pdf) | AAAI | 2020 |
| [Hindi-English Hate Speech Detection: Author Profiling, Debiasing, and Practical Perspectives](https://ojs.aaai.org/index.php/AAAI/article/view/5374/5229) | AAAI | 2020 |
| [Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective Learning](https://ojs.aaai.org/index.php/AAAI/article/view/5654) | AAAI | 2020 |
| [Adhering, Steering, and Queering: Treatment of Gender in Natural Language Generation](https://dl.acm.org/doi/10.1145/3313831.3376315) | CHI | 2020 |
| [PowerTransformer: Unsupervised Controllable Revision for Biased Language Correction](https://aclanthology.org/2020.emnlp-main.602.pdf) | EMNLP | 2020 |
| [Neutralizing Gender Bias in Word Embeddings with Latent Disentanglement and Counterfactual Generation](https://aclanthology.org/2020.findings-emnlp.280/) | EMNLP | 2020 |
| [Towards Controllable Biases in Language Generation](https://aclanthology.org/2020.findings-emnlp.291/) | EMNLP | 2020 |
| [Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology](https://aclanthology.org/P19-1161v2.pdf) | ACL | 2019 |
| [Debiasing Gender biased Hindi Words with Word-embedding](https://dl.acm.org/doi/pdf/10.1145/3377713.3377792) | ACAI | 2019 |


## Datasets for measuring bias
| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [NLPositionality: Characterizing Design Biases of Datasets and Models](https://aclanthology.org/2023.acl-long.505/) | ACL | 2023 |
| [FairPrism: Evaluating Fairness-Related Harms in Text Generation](https://aclanthology.org/2023.acl-long.343.pdf) | ACL | 2023 |
| [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias](https://arxiv.org/abs/2308.12539) | arXiv | 2023 |
| [BBQ: A hand-built bias benchmark for question answering](https://aclanthology.org/2022.findings-acl.165/) | ACL | 2022 |
| [“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset](https://aclanthology.org/2022.emnlp-main.625/) | EMNLP | 2022 |
| [StereoSet: Measuring stereotypical bias in pretrained language models](https://arxiv.org/pdf/2004.09456.pdf) | ACL | 2021 |
| [CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models](https://aclanthology.org/2020.emnlp-main.154.pdf) | EMNLP | 2020 |
| [UNQOVERing Stereotyping Biases via Underspecified Questions](https://aclanthology.org/2020.findings-emnlp.311/) | EMNLP | 2020 |
| [Evaluating models’ local decision boundaries via contrast sets](https://aclanthology.org/2020.findings-emnlp.117/) | EMNLP | 2020 |
| [Automatically Identifying Gender Issues in Machine Translation using Perturbations](https://aclanthology.org/2020.findings-emnlp.180/) | EMNLP | 2020 |
| [Winogender - Gender Bias in Coreference Resolution](https://aclanthology.org/N18-2002/) | NAACL | 2018 |

## Miscellanenous Works
These are list of papers which talks about bias in NLP and do not fit in the above categories.
| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [The Tail Wagging the Dog: Dataset Construction Biases of Social Bias Benchmarks](https://aclanthology.org/2023.acl-short.118.pdf) | ACL | 2023 |
| [From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models](https://aclanthology.org/2023.acl-long.656/) | ACL | 2023 |
| [Can Voice Assistants Be Microaggressors? Cross-Race Psychological Responses to Failures of Automatic Speech Recognition](https://dl.acm.org/doi/pdf/10.1145/3544548.3581357) | CHI | 2023 |
| [On Measures of Biases and Harms in NLP](https://arxiv.org/pdf/2108.03362.pdf) | AACL | 2022 |
| [Re-contextualizing Fairness in NLP: The Case of India](https://arxiv.org/pdf/2209.12226.pdf) | AACL | 2022 |
| [On the Intrinsic and Extrinsic Fairness Evaluation Metrics for Contextualized Language Representations](https://aclanthology.org/2022.acl-short.62/) | ACL | 2022 |
| [BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation](https://aclanthology.org/2022.emnlp-main.245.pdf) | EMNLP | 2022 |
| [Theories of “Gender” in NLP Bias Research](https://dl.acm.org/doi/10.1145/3531146.3534627) | FAccT | 2022 |
| [Using Natural Sentences for Understanding Biases in Language Models](https://aclanthology.org/2022.naacl-main.203.pdf) | NAACL | 2022 |
| [Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets](https://aclanthology.org/2021.acl-long.81/) | ACL | 2021 |
| [Persistent Anti-Muslim Bias in Large Language Models](https://dl.acm.org/doi/10.1145/3461702.3462624) | AIES | 2021 |
| [Measurement and Fairness](https://dl.acm.org/doi/pdf/10.1145/3442188.3445901) | FAccT | 2021 |
| [Unsupervised Discovery of Implicit Gender Bias](https://aclanthology.org/2020.emnlp-main.44/) | EMNLP | 2020 |
| [Women’s Syntactic Resilience and Men’s Grammatical Luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing](https://aclanthology.org/P19-1339.pdf) | ACL | 2019 |
| [Equity Beyond Bias in Language Technologies for Education](https://aclanthology.org/W19-4446/) | ACL Workshop | 2019 |
| [What is the Point of Fairness? Disability, AI, and The Complexity of Justice](https://dl.acm.org/doi/10.1145/3386296.3386301) | SIGACCESS | 2019 |
| [Addressing age-related bias in sentiment analysis](https://dl.acm.org/doi/abs/10.1145/3173574.3173986) | CHI | 2018 |
| [The Social Impact of Natural Language Processing](https://aclanthology.org/P16-2096.pdf) | ACL | 2016 |



The starting list of papers was taken from the survey paper : [Survey on Sociodemographic Bias in Natural Language Processing](https://arxiv.org/abs/2306.08158)

If you consider this repo to be useful, consider citing our work:
```
@article{gupta2023survey,
  title={Survey on Sociodemographic Bias in Natural Language Processing},
  author={Gupta, Vipul and Venkit, Pranav Narayanan and Wilson, Shomir and Passonneau, Rebecca J},
  journal={arXiv preprint arXiv:2306.08158},
  year={2023}
}
```

