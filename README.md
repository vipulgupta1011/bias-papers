# Papers on bias in NLP

Here is a list of papers focused on bias in NLP. Please feel free to send a pull request if you want to add a paper.

## Quantifying bias

| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [On Measuring and Mitigating Biased Inferences of Word Embeddings](https://arxiv.org/pdf/1908.09369.pdf) | AAAI | 2020 |
| [Evaluating Gender Bias in Machine Translation](https://aclanthology.org/P19-1164.pdf) | ACL | 2019 |
| [Understanding Undesirable Word Embedding Associations](https://aclanthology.org/P19-1166.pdf) | ACL | 2019 |
| [Bias in Bios: A Case Study of Semantic Representation Bias in a High-Stakes Setting](https://www.microsoft.com/en-us/research/uploads/prod/2019/01/bios_bias.pdf) | FAccT | 2019 |


## Bias Mitigation

| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models with Adversarial Learning](https://aclanthology.org/2022.aacl-main.61.pdf) | AACL | 2022 |
| [Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal](https://aclanthology.org/2022.findings-acl.55.pdf) | ACL | 2022 |
| [Balancing out Bias: Achieving Fairness Through Balanced Training](https://aclanthology.org/2022.emnlp-main.779.pdf)| EMNLP | 2022 |
| [Sustainable Modular Debiasing of Language Models](https://arxiv.org/pdf/2109.03646.pdf) | EMNLP | 2021 |
| [A General Framework for Implicit and Explicit Debiasing of Distributional Word Vector Spaces](https://arxiv.org/pdf/1909.06092.pdf) | AAAI | 2020 |
| [Hindi-English Hate Speech Detection: Author Profiling, Debiasing, and Practical Perspectives](https://ojs.aaai.org/index.php/AAAI/article/view/5374/5229) | AAAI | 2020 |
| [Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective Learning](https://ojs.aaai.org/index.php/AAAI/article/view/5654) | AAAI | 2020 |
| [Counterfactual Data Augmentation for Mitigating Gender Stereotypes in Languages with Rich Morphology](https://aclanthology.org/P19-1161v2.pdf) | ACL | 2019 |
| [Debiasing Gender biased Hindi Words with Word-embedding](https://dl.acm.org/doi/pdf/10.1145/3377713.3377792) | ACAI | 2019 |


## Datasets for measuring bias
| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias](https://arxiv.org/abs/2308.12539) | arXiv | 2023 |
| [“I’m sorry to hear that”: Finding New Biases in Language Models with a Holistic Descriptor Dataset](https://aclanthology.org/2022.emnlp-main.625/) | EMNLP | 2022 |
| [StereoSet: Measuring stereotypical bias in pretrained language models](https://arxiv.org/pdf/2004.09456.pdf) | ACL | 2021 |

## Miscellanenous Works
These are list of papers which talks about bias in NLP and do not fit in the above categories.
| Title | Venue | Year |
| ------------- | ------------- | ------------- |
| [Can Voice Assistants Be Microaggressors? Cross-Race Psychological Responses to Failures of Automatic Speech Recognition](https://dl.acm.org/doi/pdf/10.1145/3544548.3581357) | CHI | 2023 |
| [On Measures of Biases and Harms in NLP](https://arxiv.org/pdf/2108.03362.pdf) | AACL | 2022 |
| [Re-contextualizing Fairness in NLP: The Case of India](https://arxiv.org/pdf/2209.12226.pdf) | AACL | 2022 |
| [Theories of “Gender” in NLP Bias Research](https://dl.acm.org/doi/10.1145/3531146.3534627) | FAccT | 2022 |
| [Using Natural Sentences for Understanding Biases in Language Models](https://aclanthology.org/2022.naacl-main.203.pdf) | NAACL | 2022 |
| [Stereotyping Norwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets](https://aclanthology.org/2021.acl-long.81/) | ACL | 2021 |
| [Measurement and Fairness](https://dl.acm.org/doi/pdf/10.1145/3442188.3445901) | FAccT | 2021 |
| [The Social Impact of Natural Language Processing](https://aclanthology.org/P16-2096.pdf) | ACL | 2016 |



The starting list of papers was taken from the survey paper : [Survey on Sociodemographic Bias in Natural Language Processing](https://arxiv.org/abs/2306.08158)

If you consider this repo to be useful, consider citing our work:
```
@article{gupta2023survey,
  title={Survey on Sociodemographic Bias in Natural Language Processing},
  author={Gupta, Vipul and Venkit, Pranav Narayanan and Wilson, Shomir and Passonneau, Rebecca J},
  journal={arXiv preprint arXiv:2306.08158},
  year={2023}
}
```

